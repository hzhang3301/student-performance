---
title: "Predict student performance"
author: "xw2504"
date: "5/2/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r load_packages}
library(klaR)
library(rminer)
library(data.table)
library(plyr)
library(dplyr)
library(DT)
library(caret)
library(rpart)
library(rpart.plot)
library(ModelMetrics)
```

##construct array to save the PCC and t-value record##
```{r array_record}
level.result=matrix(nrow=3,ncol=5)
level.t=matrix(nrow=3,ncol=5)
colnames(level.result)=c('NV','NN','SVM','DT','RF')
rownames(level.result)=c('A','B','C')
colnames(level.t)=c('NV','NN','SVM','DT','RF')
rownames(level.t)=c('A','B','C')
```

##load the Portuguese data, convert the character variables to numeric ones, prepared for the later modeling##

```{r load_data, echo=FALSE}
data.file<-"/Users/xinwang/Desktop/student/student-por.csv"
at$Mjob[which(dat$Mjob=='teacher')]=1
dat$Mjob[which(dat$Mjob=='health')]=2
dat$Mjob[which(dat$Mjob=='services')]=3
dat$Mjob[which(dat$Mjob=='at_home')]=4
dat$Mjob[which(dat$Mjob=='other')]=5
dat$Fjob[which(dat$Fjob=='teacher')]=1
dat$Fjob[which(dat$Fjob=='health')]=2
dat$Fjob[which(dat$Fjob=='services')]=3
dat$Fjob[which(dat$Fjob=='at_home')]=4
dat$Fjob[which(dat$Fjob=='other')]=5
dat=read.table(data.file,sep=";",header=TRUE,stringsAsFactors = FALSE)
dat_part1=dat[,c(1:30)]
dat_part2=dat[,c(31:33)]
dat_part1[] <- lapply(dat_part1, function(x) as.numeric(as.factor(x)))
dat=cbind(dat_part1,dat_part2)
dat
```

## Divide G3 into 5 levels ##
```{r 5level_data}
dat_temp=copy(dat)
dat_temp$G3=cut(dat_temp$G3,c(-1,9,11,13,15,20),c("V","IV","III","II","I"))
dat_5level=dat_temp
```

## 5Level Classification,Input A,Naive Predictor ##
## For input A, accuracy depends on the match between G2 and G3##
```{r 5level_A_NV}
dat_5level_nv=copy(dat_5level)
dat_5level_nv$G2=cut(dat_5level_nv$G2,c(-1,9,11,13,15,20),c("V","IV","III","II","I"))
dat_equal <- dat_5level_nv[dat_5level_nv$G3==dat_5level_nv$G2,]
level.result['A','NV']=nrow(dat_equal)*100/nrow(dat_5level_nv)
level.t['A','NV']=0
```

## 5Level Classification,Input A,Neural Network Algorithm ##
## mining function in the rminer package is used to train the model, accuracy and t-value under 95% confidence interval are calculated.
```{r 5level_A_NN}
K=c('kfold',10)
A.s_nn=list(smethod='grid',search=list(size=seq(0,8,2)),method=K,convex=0)
A.NN=mining(G3~.,dat_5level,model='mlp',search=A.s_nn,maxit=100,scale='input',task='class',
          Runs=20,method=K)
savemining(A.NN,'ANN',ascii=TRUE)
A.m_nn=mmetric(A.NN,metric=c("ACC"))
level.result['A','NN']=mean(A.m_nn$ACC)
level.t['A','NN']=abs(t.test(A.m_nn$ACC)$conf.int[1]-mean(A.m_nn$ACC))
```

## 5Level Classification,Input A, SVM Algorithm ##

```{r 5level_A_SVM}
A.s_svm=list(smethod='grid',search=list(sigma=2^c(-9,-  7,-5,-3,-1)),method=K,convex=0)
A.SVM=mining(G3~.,dat_5level,model='ksvm',kernel='rbfdot',search=A.s_svm,scale='input',task='class',Runs=20,method=K)
savemining(A.SVM,'ASVM',ascii=TRUE)
A.m_svm=mmetric(A.SVM,metric=c("ACC"))
level.result['A','SVM']=mean(A.m_svm$ACC)
level.t['A','SVM']=abs(t.test(A.m_svm$ACC)$conf.int[1]-mean(A.m_svm$ACC))
```

## 5Level Classification,Input A, Decision Tree Algorithm ##
```{r 5level_A_DT}
A.DT=mining(G3~.,dat_5level,model='dt',Runs=20,task='class',method=K)
savemining(A.DT,'ADT',ascii=TRUE)
A.m_dt=mmetric(A.DT,metric=c("ACC"))
level.result['A','DT']=mean(A.m_dt$ACC)
level.t['A','DT']=abs(t.test(A.m_dt$ACC)$conf.int[1]-mean(A.m_dt$ACC))
```

## 5Level Classification,Input A,Random Forest Algorithm ##

```{r 5level_A_RF}
A.RF=mining(G3~.,dat_5level,model='randomforest',Runs=20,task='class',method=K)
savemining(A.RF,'ARF',ascii=TRUE)
A.m_rf=mmetric(A.RF,metric=c("ACC"))
level.result['A','RF']=mean(A.m_rf$ACC)
level.t['A','RF']=abs(t.test(A.m_rf$ACC)$conf.int[1]-mean(A.m_rf$ACC))
```

## 5Level Classification,Input B,Naive Predictor ##
## For input B, accuracy depends on the match between G1 and G3##

```{r 5level_B_NV}
dat_5level_nv=copy(dat_5level)
dat_5level_nv$G1=cut(dat_5level_nv$G1,c(-1,9,11,13,15,20),c("V","IV","III","II","I"))
dat_equal <- dat_5level_nv[dat_5level_nv$G3==dat_5level_nv$G1,]
level.result['B','NV']=nrow(dat_equal)*100/nrow(dat_5level_nv)
level.t['B','NV']=0
```

## 5Level Classification,Input B,Neural Network Algorithm ##

```{r 5level_B_NN}
K=c('kfold',10)
B.s_nn=list(smethod='grid',search=list(size=seq(0,8,2)),method=K,convex=0)
B.NN=mining(G3~.-G2,dat_5level,model='mlp',search=B.s_nn,maxit=100,scale='input',task='class',Runs=20,method=K)
savemining(B.NN,'BNN',ascii=TRUE)
B.m_nn=mmetric(B.NN,metric=c("ACC"))
level.result['B','NN']=mean(B.m_nn$ACC)
level.t['B','NN']=abs(t.test(B.m_nn$ACC)$conf.int[1]-mean(B.m_nn$ACC))
```

## 5Level Classification,Input B,SVM algorithm ##

```{r 5level_B_SVM}
B.s_svm=list(smethod='grid',search=list(sigma=2^c(-9,-7,-5,-3,-1)),method=K,convex=0)
B.SVM=mining(G3~.-G2,dat_5level,model='ksvm',kernel='rbfdot',search=B.s_svm,scale='input',task='class',Runs=20,method=K)
savemining(B.SVM,'BSVM',ascii=TRUE)
B.m_svm=mmetric(B.SVM,metric=c("ACC"))
level.result['B','SVM']=mean(B.m_svm$ACC)
level.t['B','SVM']=abs(t.test(B.m_svm$ACC)$conf.int[1]-mean(B.m_svm$ACC))
```

## 5Level Classification,Input B,Decision Tree Algorithm ##

```{r 5level_B_DT}
B.DT=mining(G3~.-G2,dat_5level,model='dt',Runs=20,task='class',method=K)
savemining(B.DT,'BDT',ascii=TRUE)
B.m_dt=mmetric(B.DT,metric=c("ACC"))
level.result['B','DT']=mean(B.m_dt$ACC)
level.t['B','DT']=abs(t.test(B.m_dt$ACC)$conf.int[1]-mean(B.m_dt$ACC))
```

## 5Level Classification,Input B,Random Forest Algorithm ##

```{r 5level_B_RF}
B.RF=mining(G3~.-G2,dat_5level,model='randomforest',Runs=20,task='class',method=K)
savemining(B.RF,'BRF',ascii=TRUE)
B.m_rf=mmetric(B.RF,metric=c("ACC"))
level.result['B','RF']=mean(B.m_rf$ACC)
level.t['B','RF']=abs(t.test(B.m_rf$ACC)$conf.int[1]-mean(B.m_rf$ACC))
```

## 5Level Classification,Input C,Naive Bayes ##

```{r 5level_C_NV}
C.NV=mining(G3~.-G2-G1,dat_5level,model='naive',Runs=20,task='class',method=K)
level.result['C','NV']=mean(mmetric(C.NV,metric=c("ACC"))$ACC)
level.t['C','NV']=0
```

## 5Level Classification,Input C,Neural Network ##

```{r 5level_C_NN}
K=c('kfold',10)
C.s_nn=list(smethod='grid',search=list(size=seq(0,8,2)),method=K,convex=0)
C.NN=mining(G3~.-G2-G1,dat_5level,model='mlp',search=C.s_nn,maxit=100,scale='input',task='class',Runs=20,method=K)
savemining(C.NN,'CNN',ascii=TRUE)
C.m_nn=mmetric(C.NN,metric=c("ACC"))
level.result['C','NN']=mean(C.m_nn$ACC)
level.t['C','NN']=abs(t.test(C.m_nn$ACC)$conf.int[1]-mean(C.m_nn$ACC))
```

## 5Level Classification,Input C,SVM Algorithm ##

```{r 5level_C_SVM}
C.s_svm=list(smethod='grid',search=list(sigma=2^c(-9,-7,-5,-3,-1)),method=K,convex=0)
C.SVM=mining(G3~.-G2-G1,dat_5level,model='ksvm',kernel='rbfdot',search=C.s_svm,scale='input',task='class',Runs=20,method=K)
savemining(C.SVM,'CSVM',ascii=TRUE)
C.m_svm=mmetric(C.SVM,metric=c("ACC"))
level.result['C','SVM']=mean(C.m_svm$ACC)
level.t['C','SVM']=abs(t.test(C.m_svm$ACC)$conf.int[1]-mean(C.m_svm$ACC))
```

## 5Level Classification, Input C,Decision Tree Algorithm ##

```{r 5level_C_DT}
C.DT=mining(G3~.-G2-G1,dat_5level,model='dt',Runs=20,task='class',method=K)
savemining(C.DT,'CDT',ascii=TRUE)
C.m_dt=mmetric(C.DT,metric=c("ACC"))
level.result['C','DT']=mean(C.m_dt$ACC)
level.t['C','DT']=abs(t.test(C.m_dt$ACC)$conf.int[1]-mean(C.m_dt$ACC))
```

## 5Level Classification, Input C, Random Forest Algorithm ##

```{r 5level_C_RF}
C.RF=mining(G3~.-G2-G1,dat_5level,model='randomforest',Runs=20,task='class',method=K)
savemining(C.RF,'CRF',ascii=TRUE)
C.m_rf=mmetric(C.RF,metric=c("ACC"))
level.result['C','RF']=mean(C.m_rf$ACC)
level.t['C','RF']=abs(t.test(C.m_rf$ACC)$conf.int[1]-mean(C.m_rf$ACC))
```

## save the record##
```{r write}
write.csv(level.result,"/Users/xinwang/Desktop/student/por_level.csv")
write.csv(level.t,"/Users/xinwang/Desktop/student/por_level_t.csv")
```

## plot the relative importance for best random forest models##
```{r 5level_rf_importance}
model=fit(G3~.-G2-G1,dat_5level,model="randomforest")
I=Importance(model,dat_5level)
L=list(runs=1,sen=t(I$imp),sresponses=I$sresponses)
mgraph(L,graph="IMP",leg=names(dat_5level),col=topo.colors(30),Grid=10,cex=0.45)
```

## plot the Decision Tree for the best Decision Tree model##
```{r plot_A_DT}
dt_A_5level=fit(G3~.,dat_5level,model='dt',task='class',method=K)
plot(dt_A_5level@object,uniform=TRUE,branch=0,compress=TRUE)
text(dt_A_5level@object,xpd=TRUE)
```

```{r plot_B_DT}
dt_B_5level=fit(G3~.-G2,dat_5level,model='dt',task='class',method=K)
plot(dt_B_5level@object,uniform=TRUE,branch=0,compress=TRUE)
text(dt_B_5level@object,xpd=TRUE)
```
